{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s8gre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchinfo import summary\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 7985\n",
      "    Root location: ./data/spectrograms\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(201, 81), interpolation=bilinear)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/spectrograms' #looking in subfolder train\n",
    "\n",
    "yes_no_dataset = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.Compose([transforms.Resize((201,81)),\n",
    "                                  transforms.ToTensor()\n",
    "                                  ])\n",
    ")\n",
    "print(yes_no_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class category and index of the images: {'no': 0, 'yes': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_map=yes_no_dataset.class_to_idx\n",
    "\n",
    "print(\"\\nClass category and index of the images: {}\\n\".format(class_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 6388\n",
      "Testing size: 1597\n"
     ]
    }
   ],
   "source": [
    "#split data to test and train\n",
    "#use 80% to train\n",
    "train_size = int(0.8 * len(yes_no_dataset))\n",
    "test_size = len(yes_no_dataset) - train_size\n",
    "yes_no_train_dataset, yes_no_test_dataset = torch.utils.data.random_split(yes_no_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Training size:\", len(yes_no_train_dataset))\n",
    "print(\"Testing size:\",len(yes_no_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 3241, 0: 3147})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# labels in training set\n",
    "train_classes = [label for _, label in yes_no_train_dataset]\n",
    "Counter(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    yes_no_train_dataset,\n",
    "    batch_size=15,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    yes_no_test_dataset,\n",
    "    batch_size=15,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1176, 0.1333, 0.1333, 0.1373, 0.1412, 0.1843, 0.1569, 0.1529, 0.1686,\n",
      "        0.1961, 0.1529, 0.1333, 0.1922, 0.1490, 0.1176, 0.1216, 0.1255, 0.1255,\n",
      "        0.1176, 0.1882, 0.1333, 0.2000, 0.1216, 0.1804, 0.1451, 0.1216, 0.1255,\n",
      "        0.1176, 0.1216, 0.1373, 0.1608, 0.1451, 0.1216, 0.1333, 0.1176, 0.1373,\n",
      "        0.1294, 0.1255, 0.1647, 0.1373, 0.1255, 0.1647, 0.1490, 0.1333, 0.2039,\n",
      "        0.1569, 0.1843, 0.1333, 0.1843, 0.1529, 0.1373, 0.1843, 0.1373, 0.2118,\n",
      "        0.1490, 0.1725, 0.1765, 0.1373, 0.1490, 0.1490, 0.1451, 0.1529, 0.1451,\n",
      "        0.1882, 0.1804, 0.1529, 0.1765, 0.1961, 0.1922, 0.1490, 0.1490, 0.1804,\n",
      "        0.1333, 0.1804, 0.1490, 0.1294, 0.1529, 0.1490, 0.1255, 0.1451, 0.1294])\n"
     ]
    }
   ],
   "source": [
    "td = train_dataloader.dataset[0][0][0][0]\n",
    "print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NeuronalNetwork as CNNet\n",
    "model = CNNet().to(CNNet.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function used to determine best parameters\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# used to create optimal parameters\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training function\n",
    "\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        \n",
    "        X, Y = X.to(CNNet.device), Y.to(CNNet.device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "# Create the validation/test function\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(CNNet.device), Y.to(CNNet.device)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost(pred, Y).item()\n",
    "            correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.076016  [    0/ 6388]\n",
      "loss: 0.047809  [ 1500/ 6388]\n",
      "loss: 0.098754  [ 3000/ 6388]\n",
      "loss: 0.069761  [ 4500/ 6388]\n",
      "loss: 0.228786  [ 6000/ 6388]\n",
      "\n",
      "Test Error:\n",
      "acc: 95.3%, avg loss: 0.006622\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, cost, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(15, 3, 201, 81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "class_map = ['no', 'yes']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, (X, Y) in enumerate(test_dataloader):\n",
    "        print(X)\n",
    "        X, Y = X.to(CNNet.device), Y.to(CNNet.device)\n",
    "        pred = model(X)\n",
    "        print(\"Predicted:\\nvalue={}, class_name= {}\\n\".format(pred[0].argmax(0),class_map[pred[0].argmax(0)]))\n",
    "        print(\"Actual:\\nvalue={}, class_name= {}\\n\".format(Y[0],class_map[Y[0]]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"data/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7a041d1134705da44353d01ddd658c6575333281888fab0a4d55d2b3f61ed6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
